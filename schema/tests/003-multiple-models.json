{
  "modelServer": {
    "name": "developer-model-service",
    "owner": "example-user",
    "description": "Developer model service running on vLLM",
    "usage": "Model server usage description",
    "tags": ["vLLM", "granite", "ibm"],
    "API": {
      "url": "https://api.example.com",
      "type": "openapi",
      "spec": "https://raw.githubusercontent.com/redhat-ai-dev/model-catalog-example/refs/heads/main/developer-model-service/openapi.json",
      "tags": ["openapi", "openai", "3scale"]
    },
    "lifecycle": "production",
    "authentication": true
  },
  "models": [
    {
      "name": "ibm-granite-20b",
      "description": "IBM Granite 20b model running on vLLM",
      "artifactLocationURL": "https://huggingface.co/ibm-granite/granite-20b-code-instruct",
      "tags": ["IBM", "granite", "vllm", "20b"],
      "owner": "example-user",
      "lifecycle": "production"
    },
    {
      "name": "mistral-7b",
      "description": "Mistral 7b model running on vLLM",
      "artifactLocationURL": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
      "tags": ["mistralai", "mistral", "vllm", "7b"],
      "owner": "example-user",
      "lifecycle": "production"
    },
    {
      "name": "gemma-2-2b",
      "description": "Google Gemma 2 2b model running on vLLM",
      "artifactLocationURL": "https://huggingface.co/google/gemma-2-2b",
      "tags": ["google", "gemma"],
      "owner": "example-user",
      "lifecycle": "production"
    }
  ]
}